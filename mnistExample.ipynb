{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from model.Sequential import Sequential\n",
    "from model.layers.Dense import Dense\n",
    "from model.layers.Dropout import Dropout\n",
    "from model.actiators.functional import *\n",
    "from model.tools.OneHotEncoderTools import OneHotEncoderTools\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reed\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(\"datasets/train_mnist.csv\", delimiter=\",\")\n",
    "print('reed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "raw_pyhton_dataset = []\n",
    "\n",
    "for row in data[1:]:\n",
    "    data_row = [int(row[i])/256 for i in range(1, len(row))]\n",
    "    data_row.append(int(row[0]))\n",
    "    \n",
    "    raw_pyhton_dataset.append(data_row)\n",
    "print('prepared') \n",
    "print(len(raw_pyhton_dataset))\n",
    "\n",
    "random.shuffle(raw_pyhton_dataset)\n",
    "raw_pyhton_dataset = raw_pyhton_dataset[:5000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(raw_pyhton_dataset)):\n",
    "    row = raw_pyhton_dataset[i]\n",
    "    data = OneHotEncoderTools.to_full(row[-1] + 1, 10)    \n",
    "    dataset_row = [np.array([row[:-1]]),  np.array(data)]\n",
    "    dataset.append( dataset_row )\n",
    "\n",
    "\n",
    "train_dataset = dataset[:-len(dataset)//10:1]\n",
    "test_dataset = dataset[-len(dataset)//10::1]\n",
    "\n",
    "print(train_dataset[0][1],train_dataset[1][1],train_dataset[2][1],train_dataset[3][1],train_dataset[4][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential('adam', [Dense(100, 'relu', input_shape=784), Dense(10, 'softmax')], ALPHA=0.01)\n",
    "loss_arr, accuracy_arr = model.fit(train_dataset, need_calculate_loss=False, need_calculate_accuracy=True, num_epochs=20, batch_size=10)\n",
    "print(model.calc_accuracy(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(loss_arr, label=r'$loss func$')\n",
    "plt.plot(accuracy_arr, label=r'$accuracy$')    \n",
    "plt.legend(fontsize=16)\n",
    "plt.minorticks_on()\n",
    "plt.title('Процесс обучения на \"MNIST\"')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model2 = Sequential('adam', [Dense(200, 'relu', input_shape=784), Dropout(0.5), Dense(10, 'softmax')], ALPHA=0.001)\n",
    "loss_arr, accuracy_arr = model2.fit(train_dataset, need_calculate_loss=False, need_calculate_accuracy=True, num_epochs=5, batch_size=1)\n",
    "print(model2.calc_accuracy(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_arr, label=r'$loss func$')\n",
    "plt.plot(accuracy_arr, label=r'$accuracy$')    \n",
    "plt.legend(fontsize=16)\n",
    "plt.minorticks_on()\n",
    "plt.title('Процесс обучения на \"MNIST\"')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "data = cv2.imread('images/3.png', cv2.IMREAD_GRAYSCALE)\n",
    "data = cv2.bitwise_not(data)\n",
    "cv2.imshow('seven', data)\n",
    "# cv2.waitKey(0) \n",
    "# cv2.destroyWindow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data/256\n",
    "input_data = [i for j in data for i in j]\n",
    "print(len(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(model.predict(np.array([input_data])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_dataset = []\n",
    "for row in data[1:]:\n",
    "    matrix = np.array(row[1:]).reshape((28,28))/255\n",
    "    encode_data = OneHotEncoderTools.to_full(int(row[0]), 10)\n",
    "    matrix_dataset.append((matrix, encode_data))\n",
    "\n",
    "\n",
    "random.shuffle(matrix_dataset)\n",
    "cut_dataset = matrix_dataset[:3000]\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy\n",
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete | 26.914 sec/era\n",
      "[[0.01424178 0.23771795 0.2584635  0.01014211 0.12829106 0.07820033\n",
      "  0.03793438 0.18558975 0.00822634 0.04119281]] [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5546666666666666\n"
     ]
    }
   ],
   "source": [
    "from model.Sequential import *\n",
    "from model.layers.Conv2D import *\n",
    "from model.layers.Flatten import *\n",
    "\n",
    "train_ = cut_dataset.copy()\n",
    "model = Sequential('adam', [Conv2D((3,3), linear, input_shape=(28,28)), Flatten(), Dense(100, relu), Dense(20, softZeroToOne), Dense(10, softmax)], ALPHA=0.0005)\n",
    "acc, loss, = model.fit(train_, 10, batch_size=1, need_calculate_accuracy=False)\n",
    "\n",
    "print(model.predict(cut_dataset[0][0]), cut_dataset[0][1])\n",
    "print(model.calc_accuracy(cut_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, loss, = model.fit(train_, 10, batch_size=1, need_calculate_accuracy=False)\n",
    "print(model.calc_accuracy(cut_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.tools.MathTools import *\n",
    "model.layers[3].recalculate()\n",
    "model.layers[3].get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, loss, = model.fit(train_, 15, batch_size=1, need_calculate_accuracy=False)\n",
    "print(model.calc_accuracy(cut_dataset))\n",
    "print(model.predict(cut_dataset[0][0]), cut_dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(acc, label=r'$loss func$')\n",
    "plt.plot(loss, label=r'$accuracy$')    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.predict(cut_dataset[0][0]), cut_dataset[0][1])\n",
    "model.calc_accuracy(cut_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
